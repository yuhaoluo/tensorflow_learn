{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas -i https://pypi.tuna.tsinghua.edu.cn/simple some-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    165\n",
       "1     99\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "fc = tf.feature_column\n",
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "def one_hot_cat_column(feature_name, vocab):\n",
    "  return fc.indicator_column(\n",
    "      fc.categorical_column_with_vocabulary_list(feature_name,\n",
    "                                                 vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  # Need to one-hot encode categorical features.\n",
    "  vocabulary = dftrain[feature_name].unique()\n",
    "  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(fc.numeric_column(feature_name,\n",
    "                                           dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use entire batch since this is such a small dataset.\n",
    "NUM_EXAMPLES = len(y_train)\n",
    "\n",
    "def make_input_fn(X, y, n_epochs=None, shuffle=True):\n",
    "  def input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(NUM_EXAMPLES)\n",
    "    # For training, cycle thru dataset as many times as need (n_epochs=None).\n",
    "    dataset = (dataset\n",
    "      .repeat(n_epochs)\n",
    "      .batch(NUM_EXAMPLES))\n",
    "    return dataset\n",
    "  return input_fn\n",
    "\n",
    "# Training and evaluation input functions.\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)\n",
    "#eval_input_fn = make_input_fn(dfeval, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/luoyuhao/tmp/save', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f42acc7d4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = tf.estimator.RunConfig(model_dir='/home/luoyuhao/tmp/save',\n",
    "                               keep_checkpoint_max=2)\n",
    "head = tf.estimator.RegressionHead(label_dimension=1) \n",
    "est = tf.estimator.BoostedTreesEstimator(feature_columns=feature_columns,\n",
    "                                          n_batches_per_layer=1, \n",
    "                                          head=head,\n",
    "                                          n_trees=50, \n",
    "                                          max_depth=2,\n",
    "                                          config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/luoyuhao/tmp/save/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 0.3875598, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    }
   ],
   "source": [
    "# Train model.\n",
    "est.train(train_input_fn, max_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/luoyuhao/tmp/save', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f42ceab4550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  'n_trees': 5,\n",
    "  'max_depth': 1,\n",
    "  'n_batches_per_layer': 1,\n",
    "  # You must enable center_bias = True to get DFCs. This will force the model to\n",
    "  # make an initial prediction before using any features (e.g. use the mean of\n",
    "  # the training labels for regression or log odds for classification when\n",
    "  # using cross entropy loss).\n",
    "  'center_bias': True,\n",
    "}\n",
    "\n",
    "'''\n",
    "__init__(\n",
    "    feature_columns,\n",
    "    n_batches_per_layer,\n",
    "    model_dir=None,\n",
    "    label_dimension=_HOLD_FOR_MULTI_DIM_SUPPORT,\n",
    "    weight_column=None,\n",
    "    n_trees=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    l1_regularization=0.0,\n",
    "    l2_regularization=0.0,\n",
    "    tree_complexity=0.0,\n",
    "    min_node_weight=0.0,\n",
    "    config=None,\n",
    "    center_bias=False,\n",
    "    pruning_mode='none',\n",
    "    quantile_sketch_epsilon=0.01,\n",
    "    train_in_memory=False\n",
    ")\n",
    "'''\n",
    "config = tf.estimator.RunConfig(model_dir='/home/luoyuhao/tmp/save',\n",
    "                               keep_checkpoint_max=3,\n",
    "                               save_checkpoints_steps=1000)\n",
    "\n",
    "optimizer=lambda: tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=tf.compat.v1.train.exponential_decay(\n",
    "            learning_rate=0.1,\n",
    "            global_step=tf.compat.v1.train.get_global_step(),\n",
    "            decay_steps=10000,\n",
    "            decay_rate=0.96))\n",
    "adam_optim = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=\"/home/luoyuhao/tmp/save\")\n",
    "est = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[64,32,16,16],\n",
    "    n_classes=2,\n",
    "    config=config,\n",
    "    optimizer=adam_optim,\n",
    "    warm_start_from=ws) #\n",
    "#est = tf.estimator.BoostedTreesClassifier(feature_columns,model_dir='/home/luoyuhao/tmp/save', **params)\n",
    "#est = tf.estimator.LinearClassifier(feature_columns,model_dir='/home/luoyuhao/tmp/save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/home/luoyuhao/tmp/save', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: /home/luoyuhao/tmp/save\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 10 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/luoyuhao/tmp/save/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/luoyuhao/tmp/save/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.14331841, step = 2000\n",
      "INFO:tensorflow:global_step/sec: 121.47\n",
      "INFO:tensorflow:loss = 0.13937348, step = 2100 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.868\n",
      "INFO:tensorflow:loss = 0.13938396, step = 2200 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.436\n",
      "INFO:tensorflow:loss = 0.13382979, step = 2300 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.511\n",
      "INFO:tensorflow:loss = 0.16154881, step = 2400 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.982\n",
      "INFO:tensorflow:loss = 0.150102, step = 2500 (0.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.121\n",
      "INFO:tensorflow:loss = 0.14264509, step = 2600 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.432\n",
      "INFO:tensorflow:loss = 0.13954887, step = 2700 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.356\n",
      "INFO:tensorflow:loss = 0.13355775, step = 2800 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.364\n",
      "INFO:tensorflow:loss = 0.12682381, step = 2900 (0.831 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /home/luoyuhao/tmp/save/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 128.116\n",
      "INFO:tensorflow:loss = 0.12356437, step = 3000 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.344\n",
      "INFO:tensorflow:loss = 0.121762775, step = 3100 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.935\n",
      "INFO:tensorflow:loss = 0.12035364, step = 3200 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.652\n",
      "INFO:tensorflow:loss = 0.11995664, step = 3300 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.131\n",
      "INFO:tensorflow:loss = 0.11890131, step = 3400 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.726\n",
      "INFO:tensorflow:loss = 0.11770845, step = 3500 (0.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.464\n",
      "INFO:tensorflow:loss = 0.117676914, step = 3600 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.68\n",
      "INFO:tensorflow:loss = 0.11571624, step = 3700 (0.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.318\n",
      "INFO:tensorflow:loss = 0.124016136, step = 3800 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.305\n",
      "INFO:tensorflow:loss = 0.11305225, step = 3900 (0.693 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /home/luoyuhao/tmp/save/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.11208145.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f42ac071630>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "est.train(train_input_fn, max_steps=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.768320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.646437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>2.868385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>2.868385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.445424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "accuracy                 0.772727\n",
       "accuracy_baseline        0.625000\n",
       "auc                      0.768320\n",
       "auc_precision_recall     0.646437\n",
       "average_loss             2.868385\n",
       "label/mean               0.375000\n",
       "loss                     2.868385\n",
       "precision                0.675676\n",
       "prediction/mean          0.445424\n",
       "recall                   0.757576\n",
       "global_step           4000.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation.\n",
    "results = est.evaluate(eval_input_fn)\n",
    "clear_output()\n",
    "pd.Series(results).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7689394,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.7955617,\n",
       " 'auc_precision_recall': 0.67886615,\n",
       " 'average_loss': 1.2115315,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 1.2115315,\n",
       " 'precision': 0.66101694,\n",
       " 'prediction/mean': 0.45572412,\n",
       " 'recall': 0.7878788,\n",
       " 'global_step': 2000}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model interpretation and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns_colors = sns.color_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "example = dftrain.head(1)\n",
    "class_fc = one_hot_cat_column('class', ('First', 'Second', 'Third'))\n",
    "print('Feature value: \"{}\"'.format(example['class'].iloc[0]))\n",
    "print('One-hot encoded: ', fc.input_layer(dict(example), [class_fc]).numpy())\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
